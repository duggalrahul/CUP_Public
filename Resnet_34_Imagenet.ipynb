{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compressing a Resnet-34 trained on Imagenet\n",
    "\n",
    "#### To replicate results with pretrained models please download the following models\n",
    "\n",
    "1. resnet34_imagenet_pytorch.pth\n",
    "2. resnet34_imagenet_pytorch_small_cup_t_point_60.pth\n",
    "3. resnet34_imagenet_pytorch_small_cup_t_point_65.pth\n",
    "4. resnet34_imagenet_pytorch_lr_point1_cupSS_K_point03_b_point_4.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys; sys.argv=['']; \n",
    "sys.path.insert(0, '../')\n",
    "del sys\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '3,4,5'\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import datasets, transforms\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import copy\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "\n",
    "from src.imagenet_utils import train,validate,save_checkpoint,AverageMeter,ProgressMeter\n",
    "from src.imagenet_utils import adjust_learning_rate,accuracy,adjust_learning_rate_pytorch_retrain\n",
    "from src.utils import plot_tsne,fancy_dendrogram,save_obj,load_obj\n",
    "from src.model import VGG,load_model\n",
    "from src.prune_model import prune_model\n",
    "from src.cluster_model import cluster_model\n",
    "from src.train_test import adjust_learning_rate_nips,adjust_learning_rate_iccv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify imagenet data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--data'], dest='data', nargs=None, const=None, default='/localscratch/mgh/Rahul_Imagenet/', type=<class 'str'>, choices=None, help='path to dataset', metavar='S')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch ImageNet Training')\n",
    "\n",
    "### add path to dataset here #####\n",
    "parser.add_argument('--data', type=str,default='/localscratch/mgh/Rahul_Imagenet/',metavar='S',help='path to dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parser.add_argument('--start-epoch', default=0, type=int, metavar='N',\n",
    "                    help='manual epoch number (useful on restarts)')\n",
    "parser.add_argument('-b', '--batch-size', default=256, type=int,\n",
    "                    metavar='N',\n",
    "                    help='mini-batch size (default: 256), this is the total '\n",
    "                         'batch size of all GPUs on the current node when '\n",
    "                         'using Data Parallel or Distributed Data Parallel')\n",
    "parser.add_argument('-j', '--workers', default=6, type=int, metavar='N',\n",
    "                    help='number of data loading workers (default: 4)')\n",
    "parser.add_argument('--epochs', default=90, type=int, metavar='N',\n",
    "                    help='number of total epochs to run')\n",
    "parser.add_argument('--lr', '--learning-rate', default=0.01, type=float,\n",
    "                    metavar='LR', help='initial learning rate')\n",
    "parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n",
    "                    help='momentum')\n",
    "parser.add_argument('--weight-decay', '--wd', default=1e-4, type=float,\n",
    "                    metavar='W', help='weight decay (default: 1e-4)')\n",
    "parser.add_argument('-p', '--print-freq', default=500, type=int,\n",
    "                    metavar='N', help='print frequency (default: 10)')\n",
    "parser.add_argument('--resume', default='', type=str, metavar='PATH',\n",
    "                    help='path to latest checkpoint (default: none)')\n",
    "parser.add_argument('-e', '--evaluate', dest='evaluate', action='store_true',\n",
    "                    help='evaluate model on validation set')\n",
    "parser.add_argument('--pretrained', dest='pretrained', action='store_true',\n",
    "                    help='use pre-trained model')\n",
    "parser.add_argument('--world-size', default=-1, type=int,\n",
    "                    help='number of nodes for distributed training')\n",
    "parser.add_argument('--rank', default=-1, type=int,\n",
    "                    help='node rank for distributed training')\n",
    "parser.add_argument('--dist-url', default='tcp://224.66.41.62:23456', type=str,\n",
    "                    help='url used to set up distributed training')\n",
    "parser.add_argument('--dist-backend', default='nccl', type=str,\n",
    "                    help='distributed backend')\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='disables CUDA training')\n",
    "parser.add_argument('--seed', type=int, default=12346, metavar='S',\n",
    "                    help='random seed (default: 12346)')\n",
    "parser.add_argument('--num_output', type=int, default=10, metavar='S',\n",
    "                    help='number of classes(default: 10)')\n",
    "parser.add_argument('--log-interval', type=int, default=100, metavar='N',\n",
    "                    help='how many batches to wait before logging training status')\n",
    "parser.add_argument('--checkpoint_path', type=str, default='./checkpoints/resnet34_imagenet_pytorch.pth', metavar='S',\n",
    "                    help='path to store model training checkpoints')\n",
    "parser.add_argument('--gpu', type=int, default=0, nargs='+', help='used gpu')\n",
    "parser.add_argument('--multiprocessing-distributed', action='store_true',\n",
    "                        help='Use multi-processing distributed training to launch ')#,\n",
    "#                          'N processes per node, which has N GPUs. This is the ',\n",
    "#                          'fastest way to use PyTorch for either single node or ',\n",
    "#                          'multi node data parallel training')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "# if use_cuda:\n",
    "#     print('using gpu',args.gpu)\n",
    "#     os.environ[\"CUDA_VISIBLE_DEVICES\"] = ','.join(str(x) for x in args.gpu)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "# Data loading code\n",
    "traindir = os.path.join(args.data, 'train')\n",
    "valdir = os.path.join(args.data, 'val')\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    traindir,\n",
    "    transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "train_sampler = None\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=args.batch_size, shuffle=(train_sampler is None),\n",
    "    num_workers=args.workers, pin_memory=True, sampler=train_sampler)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(valdir, transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])),\n",
    "    batch_size=args.batch_size, shuffle=False,\n",
    "    num_workers=args.workers, pin_memory=True)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().cuda(args.gpu)\n",
    "\n",
    "\n",
    "writer = SummaryWriter('logs/resnet34_imagenet/')\n",
    "\n",
    "#set all seeds for reproducability\n",
    "def set_random_seed(seed):    \n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(args.seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_random_seed(args.seed)\n",
    "\n",
    "torch.cuda.set_device(args.gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Acc@1 73.590 Acc@5 91.440\n",
      "loaded model with top1 : 73.58999633789062, top5 : 91.43999481201172\n"
     ]
    }
   ],
   "source": [
    "set_random_seed(args.seed)\n",
    "\n",
    "args.lr = 0.1\n",
    "\n",
    "resnet34 = torchvision.models.resnet34(pretrained=False)\n",
    "optimizer = torch.optim.SGD(resnet34.parameters(), args.lr,\n",
    "                            momentum=args.momentum,\n",
    "                            weight_decay=args.weight_decay)\n",
    "\n",
    "resnet34 = torch.nn.DataParallel(resnet34)\n",
    "resnet34.cuda(args.gpu)\n",
    "\n",
    "best_val_acc = 0\n",
    "\n",
    "if not os.path.isfile(args.checkpoint_path):\n",
    "    for epoch in range(args.start_epoch, args.epochs):\n",
    "        adjust_learning_rate_pytorch_retrain(optimizer, epoch, args)        \n",
    "\n",
    "        # train for one epoch\n",
    "        train_loss,train_top1,train_top5 = train(train_loader, resnet34, criterion, optimizer, epoch, args)\n",
    "\n",
    "        # evaluate on validation set\n",
    "        val_loss,val_top1,val_top5 = validate(val_loader, resnet34, criterion, args)\n",
    "        \n",
    "        if val_top1 > best_val_acc:  \n",
    "            torch.save(resnet34, args.checkpoint_path, pickle_protocol=4)            \n",
    "            best_val_acc = val_top1    \n",
    "\n",
    "        writer.add_scalars('resnet34_imagenet_pytorch_schedule/loss',{'train_loss': train_loss,\n",
    "                                        'val_loss' : val_loss}, epoch)\n",
    "        writer.add_scalars('resnet34_imagenet_pytorch_schedule/accuracy',{'train_top1': train_top1,\n",
    "                                                  'val_top1': val_top1,\n",
    "                                                  'train_top5': train_top5,\n",
    "                                                  'val_top5': val_top5}, epoch) \n",
    "else:   \n",
    "    resnet34 = torch.load(args.checkpoint_path)\n",
    "    _,val_top1,val_top5 = validate(val_loader, resnet34, criterion, args, verbose=False)\n",
    "    \n",
    "print('loaded model with top1 : {}, top5 : {}'.format(val_top1,val_top5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUP Compression summary\n",
    "\n",
    "1. T = 0.60 : large top-1 73.59, small top-1 72.73, top-1 drop 0.86, large top-5 91.44, small top-5 90.91, top-5 drop 0.53\n",
    "\n",
    "    - Number of FLOPs: 7.34G\n",
    "    - Number of FLOPs: 4.12G\n",
    "    \n",
    "2. T = 0.65 : large top-1 73.59, small top-1 71.99, top-1 drop 1.60, large top-5 91.44, small top-5 90.47, top-5 drop 0.97\n",
    "\n",
    "    + Number of FLOPs: 7.34G\n",
    "    + Number of FLOPs: 3.53G\n",
    "\n",
    "3. T = 0.675 : large top-1 73.59, small top-1 71.65, top-1 drop 1.94, large top-5 91.44, small top-5 90.21, top-5 drop 1.23\n",
    "\n",
    "    + Number of FLOPs: 7.34G\n",
    "    + Number of FLOPs: 3.20G\n",
    "    \n",
    "4. T = 0.70 : large top-1 73.59, small top-1 71.15, top-1 drop 2.44, large top-5 91.44, small top-5 90.08, top-5 drop 1.36\n",
    "\n",
    "    + Number of FLOPs: 7.34G\n",
    "    + Number of FLOPs: 2.88G\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compress using CUP (T = 0.60)\n",
    "\n",
    "- This section compresses the resnet model that we trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Acc@1 73.590 Acc@5 91.440\n",
      "loaded model with top1 : 73.58999633789062, top5 : 91.43999481201172\n"
     ]
    }
   ],
   "source": [
    "resnet34 = torch.load(args.checkpoint_path).module\n",
    "_,val_top1,val_top5 = validate(val_loader, resnet34, criterion, args, verbose=False)\n",
    "best_val_acc = val_top5\n",
    "print('loaded model with top1 : {}, top5 : {}'.format(val_top1,val_top5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Acc@1 0.616 Acc@5 2.580\n",
      " * Acc@1 72.730 Acc@5 90.910\n",
      "large top-1 73.59, small top-1 72.73, top-1 drop 0.86, large top-5 91.44, small top-5 90.91, top-5 drop 0.53\n"
     ]
    }
   ],
   "source": [
    "cluster_args = {\n",
    "    'cluster_layers' : {4:0,9:0,14:0,19:0,26:0,31:0,36:0,41:0,48:0,53:0,58:0,63:0,68:0,73:0,80:0,85:0},\n",
    "    'conv_feature_size' : 1,\n",
    "    'features' : 'both',\n",
    "    'channel_reduction' : 'fro',\n",
    "    'use_bias' : False,\n",
    "    'reshape_exists' : False,\n",
    "    'linkage_method' : 'ward',\n",
    "    'distance_metric' : 'euclidean',\n",
    "    'cluster_criterion' : 'hierarchical',\n",
    "    'distance_threshold' : 0.60,\n",
    "    'merge_criterion' : 'max_l2_norm',\n",
    "    'verbose' : False\n",
    "}\n",
    "\n",
    "path = args.checkpoint_path[:-4] + '_small_cup_t_point_60.pth' \n",
    "model_modifier = cluster_model(resnet34,cluster_args)\n",
    "resnet34_clustered = model_modifier.cluster_model()#[int(nodes*drop_percentage) for nodes in [500,300]])\n",
    "optimizer = torch.optim.SGD(resnet34_clustered.parameters(), args.lr,\n",
    "                            momentum=args.momentum,\n",
    "                            weight_decay=args.weight_decay)\n",
    "\n",
    "resnet34_clustered = torch.nn.DataParallel(resnet34_clustered)\n",
    "resnet34_clustered.cuda(args.gpu)\n",
    "\n",
    "_,top1_acc_no_retrain,top5_acc_no_retrain = validate(val_loader, resnet34_clustered, criterion, args, verbose=False)\n",
    "\n",
    "best_val_acc = 0\n",
    "\n",
    "if not os.path.isfile(path):\n",
    "    for epoch in range(args.start_epoch, args.epochs):\n",
    "        adjust_learning_rate_pytorch_retrain(optimizer, epoch, args)        \n",
    "\n",
    "        # train for one epoch\n",
    "        train_loss,train_top1,train_top5 = train(train_loader, resnet34_clustered, criterion, optimizer, epoch, args)\n",
    "\n",
    "        # evaluate on validation set\n",
    "        val_loss,val_top1,val_top5 = validate(val_loader, resnet34_clustered, criterion, args)\n",
    "        \n",
    "        if val_top1 > best_val_acc:  \n",
    "            torch.save(resnet34_clustered, path, pickle_protocol=4)            \n",
    "            best_val_acc = val_top1    \n",
    "\n",
    "        writer.add_scalars('resnet34_imagenet_t_point_60_pytorch/loss',{'train_loss': train_loss,\n",
    "                                        'val_loss' : val_loss}, epoch)\n",
    "        writer.add_scalars('resnet34_imagenet_t_point_60_pytorch/accuracy',{'train_top1': train_top1,\n",
    "                                                  'val_top1': val_top1,\n",
    "                                                  'train_top5': train_top5,\n",
    "                                                  'val_top5': val_top5}, epoch) \n",
    "else:   \n",
    "    resnet34_clustered = torch.load(path)\n",
    "    _,test_top1_acc,test_top5_acc = validate(val_loader, resnet34_clustered, criterion, args, verbose=False)\n",
    "        \n",
    "print('large top-1 {:.2f}, small top-1 {:.2f}, top-1 drop {:.2f}, large top-5 {:.2f}, small top-5 {:.2f}, top-5 drop {:.2f}'.format(val_top1,test_top1_acc,val_top1-test_top1_acc,val_top5,test_top5_acc,val_top5-test_top5_acc))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  + Number of FLOPs: 7.34G\n",
      "  + Number of FLOPs: 4.12G\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4117474673.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.compute_flops import print_model_param_nums,print_model_param_flops\n",
    "\n",
    "print_model_param_flops(resnet34.cpu(),input_res=224)\n",
    "print_model_param_flops(resnet34_clustered.module.cpu(),input_res=224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compress using CUP (T = 0.65)\n",
    "\n",
    "- This section compresses the resnet model that we trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Acc@1 73.590 Acc@5 91.440\n",
      "loaded model with top1 : 73.58999633789062, top5 : 91.43999481201172\n"
     ]
    }
   ],
   "source": [
    "resnet34 = torch.load(args.checkpoint_path).module\n",
    "_,val_top1,val_top5 = validate(val_loader, resnet34, criterion, args, verbose=False)\n",
    "best_val_acc = val_top5\n",
    "print('loaded model with top1 : {}, top5 : {}'.format(val_top1,val_top5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Acc@1 0.298 Acc@5 2.016\n",
      " * Acc@1 71.992 Acc@5 90.472\n",
      "large top-1 73.59, small top-1 71.99, top-1 drop 1.60, large top-5 91.44, small top-5 90.47, top-5 drop 0.97\n"
     ]
    }
   ],
   "source": [
    "cluster_args = {\n",
    "    'cluster_layers' : {4:0,9:0,14:0,19:0,26:0,31:0,36:0,41:0,48:0,53:0,58:0,63:0,68:0,73:0,80:0,85:0},\n",
    "    'conv_feature_size' : 1,\n",
    "    'features' : 'both',\n",
    "    'channel_reduction' : 'fro',\n",
    "    'use_bias' : False,\n",
    "    'reshape_exists' : False,\n",
    "    'linkage_method' : 'ward',\n",
    "    'distance_metric' : 'euclidean',\n",
    "    'cluster_criterion' : 'hierarchical',\n",
    "    'distance_threshold' : 0.65,\n",
    "    'merge_criterion' : 'max_l2_norm',\n",
    "    'verbose' : False\n",
    "}\n",
    "\n",
    "path = args.checkpoint_path[:-4] + '_small_cup_t_point_65.pth' \n",
    "model_modifier = cluster_model(resnet34,cluster_args)\n",
    "resnet34_clustered = model_modifier.cluster_model()#[int(nodes*drop_percentage) for nodes in [500,300]])\n",
    "optimizer = torch.optim.SGD(resnet34_clustered.parameters(), args.lr,\n",
    "                            momentum=args.momentum,\n",
    "                            weight_decay=args.weight_decay)\n",
    "\n",
    "resnet34_clustered = torch.nn.DataParallel(resnet34_clustered)\n",
    "resnet34_clustered.cuda(args.gpu)\n",
    "\n",
    "_,top1_acc_no_retrain,top5_acc_no_retrain = validate(val_loader, resnet34_clustered, criterion, args, verbose=False)\n",
    "\n",
    "best_val_acc = 0\n",
    "\n",
    "if not os.path.isfile(path):\n",
    "    for epoch in range(args.start_epoch, args.epochs):\n",
    "        adjust_learning_rate_pytorch_retrain(optimizer, epoch, args)        \n",
    "\n",
    "        # train for one epoch\n",
    "        train_loss,train_top1,train_top5 = train(train_loader, resnet34_clustered, criterion, optimizer, epoch, args)\n",
    "\n",
    "        # evaluate on validation set\n",
    "        val_loss,val_top1,val_top5 = validate(val_loader, resnet34_clustered, criterion, args)\n",
    "        \n",
    "        if val_top1 > best_val_acc:  \n",
    "            torch.save(resnet34_clustered, path, pickle_protocol=4)            \n",
    "            best_val_acc = val_top1    \n",
    "\n",
    "        writer.add_scalars('resnet34_imagenet_t_point_65_pytorch/loss',{'train_loss': train_loss,\n",
    "                                        'val_loss' : val_loss}, epoch)\n",
    "        writer.add_scalars('resnet34_imagenet_t_point_65_pytorch/accuracy',{'train_top1': train_top1,\n",
    "                                                  'val_top1': val_top1,\n",
    "                                                  'train_top5': train_top5,\n",
    "                                                  'val_top5': val_top5}, epoch) \n",
    "else:   \n",
    "    resnet34_clustered = torch.load(path)\n",
    "    _,test_top1_acc,test_top5_acc = validate(val_loader, resnet34_clustered, criterion, args, verbose=False)\n",
    "        \n",
    "print('large top-1 {:.2f}, small top-1 {:.2f}, top-1 drop {:.2f}, large top-5 {:.2f}, small top-5 {:.2f}, top-5 drop {:.2f}'.format(val_top1,test_top1_acc,val_top1-test_top1_acc,val_top5,test_top5_acc,val_top5-test_top5_acc))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  + Number of FLOPs: 7.34G\n",
      "  + Number of FLOPs: 3.53G\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3534334199.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.compute_flops import print_model_param_nums,print_model_param_flops\n",
    "\n",
    "print_model_param_flops(resnet34.cpu(),input_res=224)\n",
    "print_model_param_flops(resnet34_clustered.module.cpu(),input_res=224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try pruning alongside training the model (CUP-SS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "1. K=0.03, b = 0.3 : small top-1 71.98, small top-5 90.42\n",
    "\n",
    "  + Number of FLOPs: 7.34G\n",
    "  + Number of FLOPs: 4.30G\n",
    "\n",
    "\n",
    "2. K=0.03, b = 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K=0.03, b = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.compute_flops import print_model_param_nums,print_model_param_flops\n",
    "\n",
    "set_random_seed(args.seed)\n",
    "\n",
    "resnet34 = torchvision.models.resnet34(pretrained=False)\n",
    "resnet34_clustered = torch.nn.DataParallel(resnet34)\n",
    "resnet34_clustered.cuda(args.gpu)\n",
    "\n",
    "\n",
    "cluster_args = {\n",
    "    'cluster_layers' : {4:0,9:0,14:0,19:0,26:0,31:0,36:0,41:0,48:0,53:0,58:0,63:0,68:0,73:0,80:0,85:0},\n",
    "    'conv_feature_size' : 1,\n",
    "    'features' : 'both',\n",
    "    'channel_reduction' : 'fro',\n",
    "    'use_bias' : False,\n",
    "    'reshape_exists' : False,\n",
    "    'linkage_method' : 'ward',\n",
    "    'distance_metric' : 'euclidean',\n",
    "    'cluster_criterion' : 'hierarchical',\n",
    "    'distance_threshold' : 0.70,\n",
    "    'merge_criterion' : 'max_l2_norm',\n",
    "    'verbose' : False\n",
    "}\n",
    "\n",
    "path = args.checkpoint_path[:-4] + '_lr_point1_cupSS_K_point03_b_point_4.pth' \n",
    "\n",
    "T_values = {}\n",
    "slope,b = 0.03, 0.4\n",
    "\n",
    "for epoch in range(args.epochs+1):\n",
    "    T_values[epoch] = slope * (epoch) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Acc@1 71.688 Acc@5 90.284\n",
      "small top-1 71.69, small top-5 90.28\n"
     ]
    }
   ],
   "source": [
    "args.epochs = 90\n",
    "args.lr = 0.1\n",
    "best_val_acc = 0\n",
    "flag = True\n",
    "\n",
    "\n",
    "if not os.path.isfile(path):\n",
    "    for epoch in range(1, args.epochs+1):          \n",
    "        if epoch in T_values.keys() and flag:\n",
    "            print('changing T value to {}'.format(T_values[epoch]))\n",
    "            cluster_args['distance_threshold'] = T_values[epoch]        \n",
    "            model_modifier = cluster_model(resnet34_clustered.module,cluster_args)\n",
    "            resnet34_clustered = model_modifier.cluster_model()            \n",
    "            resnet34_clustered = torch.nn.DataParallel(resnet34_clustered)\n",
    "            resnet34_clustered.cuda(args.gpu)\n",
    "            \n",
    "            optimizer = torch.optim.SGD(resnet34_clustered.parameters(), args.lr,\n",
    "                                        momentum=args.momentum,\n",
    "                                        weight_decay=args.weight_decay)\n",
    "            T = T_values[epoch]            \n",
    "            flops = print_model_param_flops(copy.deepcopy(resnet34_clustered.module).cpu(),input_res=224)\n",
    "            if (flops/1e9 <= 4.34):\n",
    "                print('stop filter pruning')\n",
    "                flag = False\n",
    "                \n",
    "                \n",
    "        adjust_learning_rate_pytorch_retrain(optimizer, epoch, args)        \n",
    "\n",
    "        # train for one epoch\n",
    "        train_loss,train_top1,train_top5 = train(train_loader, resnet34_clustered, criterion, optimizer, epoch, args)\n",
    "\n",
    "#         evaluate on validation set\n",
    "        val_loss,val_top1,val_top5 = validate(val_loader, resnet34_clustered, criterion, args)\n",
    "        \n",
    "        if val_top1 > best_val_acc:  \n",
    "            torch.save(resnet34_clustered, path, pickle_protocol=4)            \n",
    "            best_val_acc = val_top1    \n",
    "\n",
    "        writer.add_scalars('resnet34_imagenet_lr_point1_k_point_3_b_point4/loss',{'train_loss': train_loss,\n",
    "                                        'val_loss' : val_loss}, epoch)\n",
    "        writer.add_scalars('resnet34_imagenet_lr_point1_k_point_3_b_point4/accuracy',{'train_top1': train_top1,\n",
    "                                                  'val_top1': val_top1,\n",
    "                                                  'train_top5': train_top5,\n",
    "                                                  'val_top5': val_top5}, epoch) \n",
    "       \n",
    "        writer.add_scalars('resnet34_imagenet_lr_point1_k_point_3_b_point4/flops',{'flops': flops}, epoch) \n",
    "        writer.add_scalars('resnet34_imagenet_lr_point1_k_point_3_b_point4/T',{'T': T}, epoch) \n",
    "else:\n",
    "    resnet34_clustered = torch.load(path).module\n",
    "    val_loss,val_top1,val_top5 = validate(val_loader, resnet34_clustered, criterion, args, verbose=False)\n",
    "        \n",
    "print('small top-1 {:.2f}, small top-5 {:.2f}'.format(val_top1,val_top5))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  + Number of FLOPs: 7.34G\n",
      "  + Number of FLOPs: 4.27G\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4273916483.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.compute_flops import print_model_param_nums,print_model_param_flops\n",
    "\n",
    "print_model_param_flops(resnet34.cpu(),input_res=224)\n",
    "print_model_param_flops(resnet34_clustered.cpu(),input_res=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (kdd_final)",
   "language": "python",
   "name": "kdd_final"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
